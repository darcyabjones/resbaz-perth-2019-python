{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perth ResBaz 2019 - Python Stream\n",
    "\n",
    "\n",
    "This lesson is adapted from the [Data Carpentry Ecology lesson](http://www.datacarpentry.org/python-ecology-lesson/)\n",
    "\n",
    "We'll be using an EtherPad channel to share solutions to challenges, ask questions and chat:\n",
    "\n",
    "**enter link here**\n",
    "\n",
    "\n",
    "## Download this notebook!\n",
    "\n",
    "We'll be working from this notebook and filling in the answers as we go.\n",
    "To fetch the notebook and the example data we will be using...\n",
    "\n",
    "### Please download the Git repository at <https://github.com/darcyabjones/resbaz-perth-2019-python>.\n",
    "\n",
    "If you have `git` installed you can `clone` it from the terminal at the location that you want to store it...\n",
    "\n",
    "```bash\n",
    "git clone https://github.com/darcyabjones/resbaz-perth-2019-python.git\n",
    "```\n",
    "\n",
    "\n",
    "If you don't have `git` installed, you can download a Zip archive of the repository from <https://github.com/darcyabjones/resbaz-perth-2019-python/archive/master.zip> and unzip it wherever you want :).\n",
    "\n",
    "\n",
    "## Check that you have all of the necessary packages\n",
    "\n",
    "In later sections we will be using some python packages that aren't always distributed with Python.\n",
    "If you installed the full Anaconda distribution, you should already have what you need installed.\n",
    "If you used Miniconda or another method you may need to install the packages.\n",
    "\n",
    "We will be using:\n",
    "\n",
    "- [jupyter](https://jupyter.org/)\n",
    "- [pandas](https://pandas.pydata.org/)\n",
    "- [matplotlib](https://matplotlib.org/)\n",
    "\n",
    "To check that you have these packages installed, run the following in your bash terminal (excluding the `%%bash` bit) from the directory that you downloaded this repository into."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "python3 scripts/check_packages.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are missing packages you can install them using conda (e.g. if you installed Miniconda) or pip from your terminal.\n",
    "\n",
    "```bash\n",
    "conda install -y pandas matplotlib jupyter seaborn\n",
    "\n",
    "# or\n",
    "\n",
    "python3 -m pip install --user --upgrade pip pandas matplotlib jupyter seaborn\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to use a Jupyter Notebook\n",
    "\n",
    "https://jupyter-notebook-beginner-guide.readthedocs.io/en/latest/index.html\n",
    "\n",
    "https://www.packtpub.com/books/content/getting-started-jupyter-notebook-part-1\n",
    "\n",
    "- The file autosaves\n",
    "- You run a cell with **Ctrl + enter** (or **Cmd + enter** on Mac OS) or using the run button in the tool bar\n",
    "- If you run a cell with **Shift + enter** it will also create a new cell below\n",
    "- See *Help > Keyboard Shortcuts* or the *Cheatsheet* for more info\n",
    "\n",
    "\n",
    "- The notebook has different type of cells: Code and Markdown are most commonly used\n",
    "- **Code** cells expect code for the Kernel you have chosen, syntax highlighting is available, comments in the code are specified with # -> code after this will not be executed\n",
    "- **Markdown** cells allow you to right report style text, using markdown for formatting the style (e.g. Headers, bold face etc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction to Python\n",
    "\n",
    "Python is a high-level, interpreted programming language. This means the code is easy to read for humans and there is no need for us to compile it and in many cases we do not have to think too much about the underlying system fro e.g. memory usage.\n",
    "\n",
    "As a consequence, we can use it in two ways:\n",
    "- Using the interpreter as an \"advanced calculator\" in interactive mode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing things to screen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Executing programs/scripts saved as a text file, usually with *.py extension:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# running scripts\n",
    "# Write a \"Hello World\" script using the Jupyter text editor.\n",
    "# run it from a bash terminal using the %%bash cell magic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comments in python\n",
    "\n",
    "Comments are very useful for communicating to your future self (and others) what you are doing.\n",
    "In this notebook we use them to remind us what we're doing in exercises.\n",
    "\n",
    "Comments in python (like bash) are inserted using the `#` character.\n",
    "\n",
    "They can be inserted at the beginning of lines or at the end of a line after some code.\n",
    "\n",
    "```python\n",
    "# This is a comment\n",
    "\n",
    "print(\"hello\")  # This is also a valid comment\n",
    "```\n",
    "\n",
    "\n",
    "# Types of Data\n",
    "\n",
    "How information is stored in a DataFrame or a python object affects what we can do with it and the outputs of calculations as well. There are two main types of data that we'll explore in this lesson: numeric and character types.\n",
    "\n",
    "\n",
    "## Numeric Data Types\n",
    "\n",
    "Numeric data types include integers and floats.\n",
    "A **floating point** (known as a float) number has decimal points even if that decimal point value is `0`.\n",
    "For example: `1.13`, `2.0`, `1234.345`.\n",
    "\n",
    "An **integer** will never have a decimal point.\n",
    "Thus `1.13` would be stored as `1`, and `1234.345` is stored as `1234`.\n",
    "You will often see the data type `Int64` in python which stands for 64 bit integer.\n",
    "The 64 simply refers to the amount of memory allocated to store data in each cell which effectively relates to how many digits it can store in each \"cell\".\n",
    "Allocating space ahead of time allows computers to optimize storage and processing efficiency.\n",
    "\n",
    "\n",
    "## Character Data Types\n",
    "\n",
    "Strings are values that contain numbers and/or characters. \n",
    "For example, a string might be a word, a sentence, or several sentences. \n",
    "A string can also contain or consist of numbers.\n",
    "For instance, `'1234'` could be stored as a string, as could `'10.23'`.\n",
    "However, **strings that contain numbers can not be used for mathematical operations**!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign an int, a float, and a str to the variables: number, pi_value, and text.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we've assigned data to variables, namely `text`, `number` and `pi_value`, using the assignment operator `=`.\n",
    "The variable called `text` is a string which means it can contain letters and numbers.\n",
    "We could reassign the variable `text` to an integer too - but be careful reassigning variables as this can get confusing.\n",
    "\n",
    "To print out the value stored in a variable we can simply type the name of the variable into the interpreter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the value for `text`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A cell, by default, will print to screen the last thing it evaluates (unless this is explicitly written to a variable).\n",
    "\n",
    "Thus, in scripts and for evaluating things anywhere else within a cell, we must use the `print` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next line will print out text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We also need the print statement if we want to see more than one variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the `print()` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operators\n",
    "\n",
    "We can perform mathematical calculations in Python using the basic operators\n",
    " `+, -, /, //, *, %`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Float division\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Integer division\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Python 2 the operators for integer and float division is reversed.\n",
    "So `10 / 3 == 3` and `10 // 3 == 3.333333`.\n",
    "\n",
    "If you use Python 2 (not recommended as it will be deprecated) remember to convert your integers to floats when you want floating point precision for divisions, or use the `//` operator!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to integer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to float\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use comparison and logic operators:\n",
    "`<, >, ==, !=, <=, >=` and statements of identity such as\n",
    "`and, or, not`. The data type returned by this is \n",
    "called a _boolean_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# `>` example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# `==` example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# `and` example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# `or` example\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential types: Lists and Tuples\n",
    "\n",
    "### Lists\n",
    "\n",
    "**Lists** are a common data structure to hold an ordered sequence of elements.\n",
    "Each element can be accessed by an index.\n",
    "Note that Python indexes start with 0 instead of 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list and show the first element\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A for loop can be used to access the elements in a list or other Python data structure one at a time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through the numbers list and print each element.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indentation is very important in Python.\n",
    "Note that the second line in the example above is indented.\n",
    "\n",
    "We'll look at using loops more later in the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To add elements to the end of a list, we can use the `append` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append to numbers and print the full list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Methods** are a way to interact with an object (a list, for example).\n",
    "We can invoke a method using the dot `.` followed by the method name and a list of arguments in parentheses.\n",
    "To find out what methods are available for an object, we can use the built-in `help` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find help for the numbers object\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuples\n",
    "\n",
    "A tuple is similar to a list in that it's an ordered sequence of elements.\n",
    "However, tuples can not be changed once created (they are \"immutable\").\n",
    "Tuples are created by placing comma-separated values inside parentheses `()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define two tuples, one with ints and one with strings.\n",
    "# Show the first element of one of them.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge\n",
    "1. What happens when you type `a_tuple[2] = 5` vs `a_list[1] = 5` ?\n",
    "2. Type `type(a_tuple)` into python - what is the object type?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dictionaries\n",
    "\n",
    "A dictionary or `dict` is a container that holds pairs of objects - keys and values.\n",
    "\n",
    "We define them a bit like this.\n",
    "\n",
    "```python\n",
    "translation = {'one': 1, 'two': 2}\n",
    "```\n",
    "\n",
    "Dictionaries work a lot like lists - except that you index them with keys.\n",
    "You can think about a key as a name for or a unique identifier for a set of values in the dictionary.\n",
    "Keys can only have particular types - they have to be \"hashable\".\n",
    "Strings and numeric types are acceptable, but lists aren’t."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a dictionary and access one of the values using a key.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a dictionary with integer keys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What happens if we try to use a `list` as a key?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you really want to use a collection as a key, use a tuple\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To add an item to the dictionary we assign a value to a new key:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new element to the rev dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check if a dictionary, list, or tuple contains another item using the `in` operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use in to check if 2 in rev\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using for loops with dictionaries is a little more complicated.\n",
    "We can do this in two ways using either the `.keys()` or `.items()` methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the `.keys()` method to loop through the dict and print the key value pairs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the `.items()` method to loop through the dict and print the key value pairs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge\n",
    "\n",
    "1. Print a value from the `rev` dictionary to the screen.\n",
    "2. Reassign the value in `rev` that corresponds to the key `2` so that it no longer reads `“two”` but instead `“apple-sauce”`.\n",
    "3. Print the value of `rev` to the screen again to see if the value has changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions\n",
    "\n",
    "Defining a section of code as a function in Python is done using the def keyword.\n",
    "For example a function that takes two arguments and returns their sum can be defined as:\n",
    "\n",
    "```python\n",
    "def add_function(a, b):\n",
    "    result = a + b\n",
    "    return result\n",
    "```\n",
    "\n",
    "And we call it using:\n",
    "\n",
    "```python\n",
    "z = add_function(20, 22)\n",
    "print(z)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll get some more practice defining functions later in the lesson."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Pandas and DataFrames\n",
    "\n",
    "## About Libraries\n",
    "\n",
    "A library in Python contains a set of tools (called functions) that perform tasks on our data.\n",
    "Importing a library is like getting a piece of lab equipment out of a storage locker and setting it up on the bench for use in a project.\n",
    "Once a library is set up, it can be used or called to perform many tasks.\n",
    "\n",
    "Python doesn't load all of the libraries available to it by default.\n",
    "We have to add an `import` statement to our code in order to use library functions.\n",
    "To import a library, we use the syntax `import libraryName`.\n",
    "\n",
    "You only need to load a library once during your session.\n",
    "You can load the library when needed or you can load all necessary libraries at the beginning of your script. \n",
    "This is good practice, especially for the readability of your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the builtin math library and use the sqrt function!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate a `from` import\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to give the library a nickname to shorten the command, we can add `as nickNameHere`.\n",
    "An example of importing the pandas library using the common nickname `pd` is below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas in Python\n",
    "\n",
    "One of the best options for working with tabular data in Python is to use the [Python Data Analysis Library](http://pandas.pydata.org/) (a.k.a. Pandas).\n",
    "The Pandas library provides data structures, produces high quality plots with [matplotlib](http://matplotlib.org/) and integrates nicely with other libraries that use [NumPy](http://www.numpy.org/) (which is another Python library) arrays.\n",
    "\n",
    "A handy **Pandas cheatsheet** can be found [here](http://pandas.pydata.org/Pandas_Cheat_Sheet.pdf).\n",
    "\n",
    "Each time we call a function that's in a library, we use the syntax `LibraryName.FunctionName`.\n",
    "Adding the library name with a `.` before the function name tells Python where to find the function.\n",
    "In the example above, we have imported Pandas as `pd`.\n",
    "This means we don't have to type out `pandas` each time we call a Pandas function.\n",
    "\n",
    "\n",
    "## So What's a DataFrame?\n",
    "\n",
    "A DataFrame is a 2-dimensional (labeled) data structure that stores data of different types (including characters, integers, floating point values, factors and more) in columns.\n",
    "\n",
    "It is similar to a spreadsheet or an SQL table or the `data.frame` in R. \n",
    "\n",
    "A DataFrame always has an index (0-based) and works best with *tidy data*.\n",
    "According to [Hadley Wickham](http://vita.had.co.nz/papers/tidy-data.html):\n",
    "> Tidy datasets are easy to manipulate, model and visualize, and have a specific structure: each variable is a column, each observation is a row, and each type of observational unit is a table. \n",
    "\n",
    "More info on the pandas DataFrame: https://pandas.pydata.org/pandas-docs/stable/dsintro.html#dataframe\n",
    "\n",
    "\n",
    "## Reading data into a pandas DataFrame\n",
    "\n",
    "### Our Data \n",
    "\n",
    "For this lesson, we will be using the Portal Teaching data, a subset of the data from Ernst et al [Long-term monitoring and experimental manipulation of a Chihuahuan Desert ecosystem near Portal, Arizona, USA](http://www.esapubs.org/archive/ecol/E090/118/default.htm).\n",
    "\n",
    "We will be using files from the [Portal Project Teaching Database](https://figshare.com/articles/Portal_Project_Teaching_Database/1314459).\n",
    "This section will use the `surveys.csv` file which can be found in the `data/` directory.\n",
    "\n",
    "We are studying the species and weight of animals caught in plots in our study\n",
    "area. The dataset is stored as a `.csv` file: each row holds information for a\n",
    "single animal, and the columns represent:\n",
    "\n",
    "| Column           | Description                        |\n",
    "|------------------|------------------------------------|\n",
    "| record_id        | Unique id for the observation      |\n",
    "| month            | month of observation               |\n",
    "| day              | day of observation                 |\n",
    "| year             | year of observation                |\n",
    "| plot             | ID of a particular plot            |\n",
    "| species          | 2-letter code                      |\n",
    "| sex              | sex of animal (\"M\", \"F\")           |\n",
    "| wgt              | weight of the animal in grams      |\n",
    "\n",
    "\n",
    "The first few rows of our first file look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Show the first few lines of data/surveys.csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Starting in the same spot\n",
    "\n",
    "To help the lesson run smoothly, let's ensure everyone is in the same directory.\n",
    "This should help us avoid path and file name issues. \n",
    "\n",
    "At this time please navigate to the workshop directory (i.e. the directory with the notebooks in them). \n",
    "If you working in Jupyter Notebook be sure that you start your notebook in the workshop directory.\n",
    "\n",
    "A quick aside, there are Python libraries like [`os`](https://docs.python.org/3/library/os.html) that can work with our\n",
    "directory structure, however, that is not our focus today."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that you are in the right working directory.\n",
    "\n",
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you need to change your directory enter into a new cell.\n",
    "\n",
    "```python\n",
    "import os\n",
    "\n",
    "os.chdir(\"where/to/change/to\")\n",
    "```\n",
    "\n",
    "`chdir` in python is analogous to `cd` in bash.\n",
    "\n",
    "You can also list all files in the current working directory `./` using the `os.listdir()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(\"./\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading data with pandas\n",
    "\n",
    "We will begin by locating and reading our survey data `surveys.csv` which are in CSV format.\n",
    "We can use Pandas' `read_csv` function to pull the file directly into a\n",
    "[DataFrame](http://pandas.pydata.org/pandas-docs/stable/dsintro.html#dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note that pd.read_csv is used because we imported pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there were 33,549 rows parsed.\n",
    "Each row has 9 columns.\n",
    "\n",
    "The first column is the index of the DataFrame.\n",
    "The index is used to identify the position of the data, but it is not an actual column of the DataFrame. \n",
    "\n",
    "It looks like  the `read_csv` function in Pandas read our file properly.\n",
    "However, we haven't saved any data to memory so we can work with it.\n",
    "We need to assign the DataFrame to a variable.\n",
    "Remember that a variable is a name for a value, such as `x`, or  `data`.\n",
    "\n",
    "We can create a new object with a variable name by assigning a value to it using `=`.\n",
    "\n",
    "Let's call the imported survey data `surveys_df`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data and assign it to the variable `surveys_df`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice when you assign the imported DataFrame to a variable, Python does not produce any output on the screen.\n",
    "We can print the value of the `surveys_df` object by typing its name into the Python command prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display surveys_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manipulating Our Species Survey Data\n",
    "\n",
    "Now we can start manipulating our data.\n",
    "First, let's check the data type of the data stored in `surveys_df` using the `type` method.\n",
    "The `type` function tell us that `surveys_df` is `pandas.core.frame.DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the type of surveys_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also access the types of individual columns with the DataFrame attribute `surveys_df.dtypes`.\n",
    "\n",
    "- `int64` represents numeric integer values - `int64` cells can not store decimals.\n",
    "- `float64` represents numbers with decimals.\n",
    "- `object` represents strings (letters and numbers).\n",
    "\n",
    "\n",
    "Unlike in python lists, elements of columns in Pandas must all be the same type.\n",
    "If we have a column that contains both integers and floating point numbers, Pandas will assign the entire column to the float data type so the decimal points are not lost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the dtypes of surveys_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas and base Python use slightly different names for data types. More on this\n",
    "is in the table below:\n",
    "\n",
    "| Pandas Type | Native Python Type | Description |\n",
    "|-------------|--------------------|-------------|\n",
    "| object | string | The most general dtype. Will be assigned to your column if column has mixed types (numbers and strings). |\n",
    "| int64  | int | Numeric characters. 64 refers to the memory allocated to hold this character. |\n",
    "| float64 | float | Numeric characters with decimals. If a column contains numbers and NaNs(see below), pandas will default to float64, in case your missing value has a decimal. |\n",
    "| datetime64, timedelta[ns] | N/A (but see the [datetime] module in Python's standard library) | Values meant to hold time data. Look into these for time series experiments. |\n",
    "\n",
    "[datetime]: http://doc.python.org/3/library/datetime.html\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenges\n",
    "\n",
    "Try out the methods below to see what they return.\n",
    "\n",
    "1. `surveys_df.columns`.\n",
    "2. `surveys_df.head()`. Also, what does `surveys_df.head(15)` do?\n",
    "3. `surveys_df.tail()`.\n",
    "4. `surveys_df.shape`. Take note of the output of the shape method. What format does it return the shape of the DataFrame in?\n",
    "\n",
    "HINT: [More on tuples, here](https://docs.python.org/3/tutorial/datastructures.html#tuples-and-sequences)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring DataFrames in Python\n",
    "\n",
    "There are multiple methods and attributes that can be used to access and summarise the data stored in DataFrames.\n",
    "Let's try out a few.\n",
    "Note that we call the method or access the attribute by using the object name followed by `.` and the method or attribute name.\n",
    "\n",
    "So `surveys_df.columns` provides an index of all of the column names in our DataFrame stored in the attribute `columns`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting Data Using Labels (Column Headings)\n",
    "\n",
    "\n",
    "In pandas you can use several ways to **select a specific column**:\n",
    "- square brackets `[]` \n",
    "- a `.` and the column name\n",
    "\n",
    "For example, we can select all of data from a column named `species` from the `surveys_df`\n",
    "DataFrame by name:\n",
    "\n",
    "```python\n",
    "surveys_df['species']\n",
    "\n",
    "# this syntax, calling the column as an attribute, gives you the same output\n",
    "surveys_df.species\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the species column in `surveys_df` using [].\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the species column in `surveys_df` as an attribute.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using double square brackets `[[]]` we can pass a list of column names too by listing the names we want:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the columns 'record_id' and 'species' using a list.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also assign the column object to a new variable using the `=` operator as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an object named surveys_species that only contains the `species_id` column\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns returned are another Pandas object called a `Series`.\n",
    "A `Series` is pandas' way of representing columns or rows, as well as their \"indexes\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What's the type of surveys_species?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the dtype of the Series?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** If a column name is not contained in the DataFrame, an exception\n",
    "(error) will be raised.\n",
    "\n",
    "```python\n",
    "surveys_df['speciess']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What happens if we try to access 'speciess'?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "We can convert columns to different data types using the `.astype()` method on a `Series`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remind ourselves what the .dtypes are\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the record_id column from an integer to a float using .astype()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens if we try to convert float weight values to integers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the `wgt` column from a float to an integer using .asdtype\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that this throws a value error: `ValueError: Cannot convert non-finite values (NA or inf) to integer`.\n",
    "\n",
    "If we look at the `wgt` column in the surveys data we notice that there are `NaN` (Not A Number) values.\n",
    "`NaN` values are undefined values that cannot be represented mathematically.\n",
    "Pandas, for example, will read an empty cell in a CSV or Excel sheet as a `NaN`.\n",
    "\n",
    "`NaN`s have some desirable properties: if we were to average the `weight` column without replacing our NaNs, Python would know to skip over those cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the mean of the `wgt` column using the `.mean()` method.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Note: older pandas version do not know how to handle `NaN`, please update to v0.19 or higher_\n",
    "\n",
    "Check your pandas version using `pd.__version__`, if you need to update open a bash terminal (or use Jupyter cell magic) and type ```conda update pandas```.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Data Values - NaN\n",
    "\n",
    "Dealing with missing data values is always a challenge.\n",
    "It's sometimes hard to know why values are missing - was it because of a data entry error?\n",
    "Or data that someone was unable to collect?\n",
    "Should the value be 0?\n",
    "\n",
    "We need to know how missing values are represented in the dataset in order to make good decisions.\n",
    "If we're lucky, we have some metadata that will tell us more about how null values were handled.\n",
    "\n",
    "\n",
    "For instance, in some disciplines, like Remote Sensing, missing data values are often defined as -9999.\n",
    "Having a bunch of -9999 values in your data could really alter numeric calculations.\n",
    "\n",
    "Often in spreadsheets, cells are left empty where no data are available.\n",
    "Pandas will, by default, replace those missing values with `NaN`.\n",
    "However it is good practice to get in the habit of intentionally marking cells that have no data, with a no data value! That way there are no questions in the future when you (or someone else) explores your data.\n",
    "\n",
    "\n",
    "### Where Are the NaN's?\n",
    "\n",
    "Let's explore the `NaN` values in our data a bit further. \n",
    "First, let's figure out **how many rows contain NaN values for weight**. \n",
    "\n",
    "We can do this by identifying how many rows have a NULL value (`.isnull`) or by counting the number of rows that have a meaningful value (e.g. `wgt > 0`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remind ourselves how many values are in the df.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use `.isnull` method to find `NaN` values.\n",
    "# Count number of NaN values with sum or subsetting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the number of records with weight > 0 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can replace all `NaN` values with zeroes using the `.fillna()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fill na values in wgt with 0 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make a change to a `DataFrame` permanent, we assign the updated `Series` back to the `DataFrame` column accessor with `=` (after making a copy of the data so we don't lose our work. We'll revisit copying data later)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the dataframe using the `.copy()` method\n",
    "\n",
    "\n",
    "# replace NaN with 0 using the `.fillna()` method\n",
    "\n",
    "\n",
    "# Show the updated dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, `NaN` and `0` yield different analysis results. The mean value when `NaN`\n",
    "values are replaced with `0` is different from when `NaN` values are simply thrown\n",
    "out or ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check mean of weights in the new na filled dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how does the new mean differ from before?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can fill `NaN` values with any value that we chose.\n",
    "The code below fills all `NaN` values with a mean for all weight values.\n",
    "\n",
    "```python\n",
    " df1['wgt'] = surveys_df['wgt'].fillna(surveys_df['wgt'].mean())\n",
    "```\n",
    "\n",
    "We could also chose to create a subset of our data, only keeping rows that do not contain `NaN` values, using the `.dropna()` method.\n",
    "\n",
    "**The point is to make conscious decisions about how to manage missing data.**\n",
    "\n",
    "This is where we think about how our data will be used and how these values will\n",
    "impact the scientific conclusions made from the data.\n",
    "\n",
    "Python gives us all of the tools that we need to account for these issues. We\n",
    "just need to be cautious about how the decisions that we make impact scientific\n",
    "results.\n",
    "\n",
    "### Brief aside about `inplace`\n",
    "\n",
    "The pattern of modifying a column and reassigning it to the same column in a DataFrame is very common.\n",
    "In Pandas, many methods have an optional `inplace` argument.\n",
    "\n",
    "Setting it to `True` will modify the column \"in place\".\n",
    "\n",
    "E.G. The following is equivalent to what we did with `df1` previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = surveys_df.copy()\n",
    "\n",
    "df2[\"wgt\"].fillna(0, inplace=True)\n",
    "df2[\"wgt\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating summary statistics for a Pandas DataFrame\n",
    "\n",
    "We've read our data into Python. Next, let's perform some quick summary\n",
    "statistics to learn more about the data that we're working with. We might want\n",
    "to know how many animals were collected in each plot, or how many of each\n",
    "species were caught. We can perform summary stats quickly using groups. But\n",
    "first we need to figure out what we want to group by.\n",
    "\n",
    "---\n",
    "\n",
    "Let's find out how many unique plot IDs and species we have in our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reminder of the column names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of unique plot_names in `plot` and species in `species` found in the surveys data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the length of the list\n",
    "print(\"There are: \" + str(len(plot_names)) + \" unique plots in the data\")\n",
    "print(\"There are: \" + str(len(species)) + \" unique species in the data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single line solution\n",
    "print(\"There are: \" + str(surveys_df['plot'].nunique()) + \" unique plots in the data\")\n",
    "print(\"There are: \" + str(surveys_df['species'].nunique()) + \" unique species in the data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why might the numbers be different using the two methods?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "\n",
    "The Pandas method `.describe()` will return descriptive stats including: `mean`, `median`, `max`, `min`, `std` and `count` for a particular column in the data or the whole dataframe.\n",
    "However, the `.describe()` method will only return summary values for columns containing numeric data.\n",
    "\n",
    "We can calculate basic statistics for all records in a single column using the syntax below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find descriptive statistics for `wgt` using the `.describe()` method.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find descriptive statistics for the whole dataframe using the `.describe()` method.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the `species` and `sex` are not in the summaries because they are not numeric columns.\n",
    "\n",
    "\n",
    "We can also extract one specific metric if we wish:\n",
    "\n",
    "```python\n",
    "surveys_df['wgt'].min()\n",
    "surveys_df['wgt'].max()\n",
    "surveys_df['wgt'].mean()\n",
    "surveys_df['wgt'].std()\n",
    "surveys_df['wgt'].count()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count values in the `wgt` column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the minimum of values in the `wgt` column\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Maths Functions\n",
    "\n",
    "If we wanted to, we could perform maths operations on an entire column of our data.\n",
    "For example let's multiply all weight values by 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# multiply all values in `wgt` by 2 using the * operator\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A more practical use of this might be to normalize the data according to a mean, area, or some other value calculated from our data.\n",
    "\n",
    "Unfortunately this shorthand is specific to Pandas (and numpy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What happens if we try multiply or add a python list by 2?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Groups in Pandas\n",
    "\n",
    "We often want to calculate summary statistics grouped by subsets or attributes\n",
    "within fields of our data, for example we might want to know what the summary stats look like split by sex.\n",
    "We can use Pandas DataFrames' `.groupby()` method, which creates a groupby DataFrame on which we can perform other pandas methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grouping the df by sex into `by_sex`\n",
    "\n",
    "\n",
    "# summary statistics for this new df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the type of `by_sex`?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# provide the min for each numeric column by sex\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `.groupby()` method is powerful in that it allows us to quickly generate\n",
    "summary stats, not just for one group but several.\n",
    "\n",
    "For example, we might want to calculate the average\n",
    "weight of all individuals per plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate average `wgt` of individuals for each `plot`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, we might want to know how many males and females we have for each species:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of `record_id` for each `sex` and `species`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another quick way to get the count of each unique value in a column is the `.value_counts()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count unique values in the `sex` column grouped by `species` using the `.value_counts()` method\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge\n",
    "\n",
    "\n",
    "1. What happens when you group by two columns using the following syntax and\n",
    "    then grab mean values:\n",
    "\t- `sorted_data = surveys_df.groupby(['plot','species'])`\n",
    "\t- `sorted_data.mean()`\n",
    "2. Get summary statistics on the weight for grouped by the plot, species and sex.\n",
    "   HINT: you can use the following syntax to only create summary statistics for \n",
    "   one column in your data `name_of_grouped_dataframe['name_of_column'].describe()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick & Easy Plotting Data Using Pandas\n",
    "\n",
    "We can plot our summary stats using Pandas too using the `.plot()` method on dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure figures appear inline in Jupyter Notebook\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "\n",
    "# plot scatter plot of year vs wgt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a quick bar chart looking at counts of species.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also look at how many animals were captured in each plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find how many records are in each plot\n",
    "\n",
    "\n",
    "# let's plot a barchart of that too\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge Activities\n",
    "\n",
    "1. Create a line plot of average weight across all species per plot. x-axis = plot, y-axis = wgt\n",
    "2. Create the same plot but with average weight for each sex per plot.\n",
    "   Hint, you will need to `unstack` when plotting.\n",
    "   x-axis = plot, y-axis = wgt, different lines for each sex.\n",
    "3. Create a trend plot of the average weight per plot over time.\n",
    "   x-axis = year, y-axis = wgt, different lines for each plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group by `plot` and calculate mean `wgt`\n",
    "\n",
    "\n",
    "# let's plot, you should have x-axis = \"plot\", y-axis = \"wgt\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group by plot and sex, then calculate mean wgt\n",
    "\n",
    "\n",
    "# call the `.unstack()` method on your grouped series and assign it to another variable. \n",
    "\n",
    "\n",
    "# let's plot on the unstacked object, you should have x-axis = plot, y-axis = wgt, different lines for sex\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group by year and plot, then calculate mean wgt\n",
    "\n",
    "\n",
    "# let's plot, you should have x-axis = year, y-axis = wgt, different lines for plot\n",
    "# you need to use the .unstack() method before the .plot() for this to work\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Indexing & Slicing in Python\n",
    "\n",
    "We often want to work with subsets of a DataFrame object. There are\n",
    "different ways to accomplish this including: using labels (ie, column headings - as used previously),\n",
    "numeric ranges or specific row and column index locations.\n",
    "\n",
    "## Extracting Range based Subsets: Slicing\n",
    "\n",
    "**REMINDER**: Python Uses 0-based Indexing\n",
    "\n",
    "Let's remind ourselves that Python uses 0-based indexing.\n",
    "This means that the first element in an object is located at position `0`.\n",
    "\n",
    "This is different from other tools like R and Matlab that index elements within objects starting at 1.\n",
    "\n",
    "\n",
    "\n",
    "![indexing diagram](https://datacarpentry.org/python-ecology-lesson/fig/slicing-indexing.png)\n",
    "\n",
    "![slicing diagram](https://datacarpentry.org/python-ecology-lesson/fig/slicing-slicing.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenges\n",
    "\n",
    "```python\n",
    "# Create a list of numbers:\n",
    "a = [1, 2, 3, 4, 5]\n",
    "```\n",
    "\n",
    "1. What value does the code below return?\n",
    "   ```python\n",
    "   a[0]\n",
    "   ```\n",
    "2. What about this?\n",
    "   ```python\n",
    "   a[-1]\n",
    "   ```\n",
    "2. What about a slice?\n",
    "   ```python\n",
    "   a[2:3]\n",
    "   ```\n",
    "3. How about this:\n",
    "   ```python\n",
    "   a[5]\n",
    "   ```\n",
    "4. Or this?\n",
    "   ```python\n",
    "   a[len(a)]\n",
    "   ```\n",
    "5. In the example above, calling `a[5]` returns an error. Why is that?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slicing using the `[]` operator\n",
    "\n",
    "Slicing using the `[]` operator selects a set of rows and/or columns from a DataFrame.\n",
    "To slice out a set of rows, you use the following syntax: `data[start:stop]`.\n",
    "\n",
    "When slicing, the start bound is included in the output.\n",
    "The stop bound is one step BEYOND the row you want to select.\n",
    "So if you want to select rows 0, 1 and 2 your code would look like this:\n",
    "\n",
    "\n",
    "```python\n",
    "# select rows 0,1,2 (but not 3)\n",
    "surveys_df[0:3]\n",
    "```\n",
    "\n",
    "The stop bound in Python is different from what you might be used to in\n",
    "languages like Matlab and R.\n",
    "\n",
    "```python\n",
    "# select the first, second and third rows from the surveys variable\n",
    "surveys_df[0:3]\n",
    "# select the first 5 rows (rows 0,1,2,3,4)\n",
    "surveys_df[:5]\n",
    "# select the last element in the list\n",
    "surveys_df[-1:]\n",
    "```\n",
    "\n",
    "To access columns we will need to call them by their labels, if you want more than one column you need to supply a list of column names.\n",
    "\n",
    "```python\n",
    "# selecting the plot column\n",
    "surveys_df['plot']\n",
    "\n",
    "# selecting plot and weight\n",
    "surveys_df[['plot','wgt']]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the last row of the dataframe using a slice.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the rows 0, 1, and 4 of the plot column using a list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the first three rows of the plot column using a slice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the first three rows of the `plot`, `wgt` sub-dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also reassign values within subsets of our DataFrame.\n",
    "But while we do that, let's assign our DataFrame to a new variable to demonstrate something that you might not expect.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the surveys_df to a new variable surveys_copy to avoid modifying the original DataFrame\n",
    "\n",
    "\n",
    "# Reassign the first three rows of data in the new DataFrame variable to 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the head of the copied dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the head of the original dataframe.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the difference between the two data frames?\n",
    "\n",
    "What happens if you copy the following blocks and run them?\n",
    "\n",
    "```python\n",
    "numbers = [1, 2, 3, 4]\n",
    "numbers_copy = numbers\n",
    "numbers_copy[1:3] = [0, 0]\n",
    "\n",
    "print(numbers)\n",
    "```\n",
    "\n",
    "or this?\n",
    "\n",
    "```python\n",
    "number = 1\n",
    "number_copy = number\n",
    "\n",
    "number_copy = 0\n",
    "print(number)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Referencing Objects vs Copying Objects in Python\n",
    "\n",
    "We might have thought that we were creating a fresh copy of the `surveys_df` objects when we  used the code `surveys_copy = surveys_df`.\n",
    "However the statement `y = x` doesn’t create a copy of our DataFrame.\n",
    "It creates a new variable `y` that refers to the **same** object `x` refers to.\n",
    "This means that there is only one object (the DataFrame), and both `x` and `y` refer to it.\n",
    "So when we assign the first 3 columns the value of `0` using the `surveys_copy` DataFrame, the `surveys_df` DataFrame is modified too.\n",
    "\n",
    "To create a fresh copy of the `surveys_df` DataFrame we use the syntax `y = x.copy()`.\n",
    "But before we have to read the `surveys_df` again because the current version contains the unintentional changes made to the first 3 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data/surveys.csv again\n",
    "\n",
    "\n",
    "# Copy it to a new variable with the `.copy()` method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reassign the first three rows of data in the new DataFrame variable to 0\n",
    "\n",
    "\n",
    "# show the head of the original dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `.copy()` method is another thing that is specific to Pandas.\n",
    "\n",
    "To copy objects in general you can use the builtin [`copy`](https://docs.python.org/3/library/copy.html) package.\n",
    "The syntax for copying a `list` would be:\n",
    "\n",
    "```python\n",
    "import copy\n",
    "\n",
    "numbers = [1, 2, 3, 4, 5]\n",
    "numbers_copy = copy.deepcopy(numbers)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slicing and subsetting: label vs integer-based indexing\n",
    "\n",
    "We can select specific locations or ranges of our data in both the row and column directions\n",
    "using either label or integer-based indexing.\n",
    "\n",
    "- `loc`: indexing via *labels* (which can be numbers)\n",
    "- `iloc`: indexing via *integers*\n",
    "\n",
    "\n",
    "<img src=\"http://104.236.88.249/wp-content/uploads/2016/10/Pandas-selections-and-indexing.png\" alt=\"loc_iloc_subsetting\" width=\"550px\" />\n",
    "\n",
    "<img src=\"https://vrzkj25a871bpq7t1ugcgmn9-wpengine.netdna-ssl.com/wp-content/uploads/2019/01/pandas-dataframe-has-indexes.png\" alt=\"dataframe_indexing\" width=\"600px\" />\n",
    "\n",
    "\n",
    "To select an index subset of rows AND columns from our DataFrame, we can use the `iloc` method.\n",
    "For example, we can select RA, Dec and number of votes (columns 2, 3 and 4 if we start counting at 1), by slicing our index like this:\n",
    "\n",
    "```python\n",
    "surveys_df.iloc[0:3, 1:4]\n",
    "```\n",
    "\n",
    "**Note**: the order of selection is ROW followed by COLUMN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you haven't done so yet read the csv back in (we had unwanted changes when \n",
    "# we 'copied' the data frame earlier)\n",
    "\n",
    "\n",
    "# try .iloc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we asked for a slice from `0:3`. This yielded 3 rows of data. When you\n",
    "ask for `0:3`, you are actually telling python to start at index 0 and select rows\n",
    "`0`, `1`, and `2` (**up to but not including 3**).\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "Next let's explore subsetting our data using labels.\n",
    "**Note** When \"slicing\" labels, the start bound and the stop bound are **included**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select all columns for rows of index values 0 and 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what does this do?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What happens when you type the code below?\n",
    "surveys_df.loc[[0, 10, 35549], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try using iloc instead?\n",
    "surveys_df.iloc[[0, 10, 35549], :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: If using `iloc` labels must be found in the DataFrame or you will get a `KeyError`.\n",
    "Using `loc` (at least for now) you'll get `NaN` entries returned so be careful!\n",
    "\n",
    "\n",
    "## Challenge Activities\n",
    "\n",
    "1. What happens when you type:\n",
    "\t- `surveys_df[0:3]`\n",
    "\t- `surveys_df[:5]`\n",
    "\t- `surveys_df[-1:]`\n",
    "\n",
    "2. What happens when you call:\n",
    "    - `dat.iloc[0:4, 1:4]`\n",
    "    - `dat.loc[0:4, 1:4]`\n",
    "    - How are the two commands different?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subsetting using masks\n",
    "\n",
    "A mask can be useful to locate where a particular subset of values exist or don't exist - for example, `NaN`, or \"Not a Number\" values.\n",
    "\n",
    "To understand masks we also need to understand `bool` objects in python.\n",
    "\n",
    "Boolean values include `True` or `False`.\n",
    "So for example:\n",
    "\n",
    "```python\n",
    "# set x to 5\n",
    "x = 5\n",
    "\n",
    "# what does the code below return?\n",
    "x > 5\n",
    "\n",
    "# how about this?\n",
    "x == 5\n",
    "```\n",
    "\n",
    "When we ask python what the value of `x > 5` is, we get `False`.\n",
    "This is because `x` is not greater than 5 it is equal to 5.\n",
    "To create a boolean mask, you first create the `True` / `False` criteria (e.g. `values > 5`).\n",
    "Python will then assess each value in the object to determine whether the value meets the criteria (`True`) or not (`False`).\n",
    "Python creates an output object that is the same shape as the original object, but with a `True` or `False` value for each index location.\n",
    "\n",
    "You can use the syntax below when querying data from a DataFrame.\n",
    "Experiment with selecting various subsets of our data.\n",
    "\n",
    "* Equals: `==`\n",
    "* Not equals: `!=`\n",
    "* Greater than, less than: `>` or `<`\n",
    "* Greater than or equal to `>=`\n",
    "* Less than or equal to `<=`\n",
    "\n",
    "Let's try this out. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Select all rows with `wgt` < 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select all rows with `wgt` > 100 and `sex` == \"F\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the use of the `&` operator, which is a bit like `and` but in Pandas it does the `and` for each element of a `Series`.\n",
    "\n",
    "\n",
    "Next, let's identify all locations in the survey data that have null (missing or `NaN`) data values. We can use the pandas `isnull` function to do this.\n",
    "Each cell with a null value will be assigned a value of  `True` in the new boolean object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Use is null to find all null values in the dataframe\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To select the rows where there are null values, we can use the mask as an index to subset our data as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# To select just the rows with NaN values in any column, we can use the .any() method\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that there are many null or `NaN` values in the `wgt` column of our DataFrame.\n",
    "We explored different ways of dealing with these earlier in this notebook.\n",
    "\n",
    "We can run `isnull` on a particular column too.\n",
    "What does the code below do?\n",
    "\n",
    "```python\n",
    "# what does this do?\n",
    "empty_weights = surveys_df.loc[pd.isnull(surveys_df[\"wgt\"])]\n",
    "```\n",
    "\n",
    "Let's take a minute to look at the statement above. \n",
    "\n",
    "We are using the Boolean object as an index. \n",
    "We are asking python to select rows that have a `NaN` value for weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge Activities\n",
    "\n",
    "1. Select a subset of rows in the `surveys_df` DataFrame that contain data from\n",
    "   the year 1999 and that contain weight values less than or equal to 8. How\n",
    "   many columns did you end up with? What did your neighbor get?\n",
    "2. You can use the `isin` command in python to query a DataFrame based upon a\n",
    "   list of values as follows:\n",
    "   `surveys_df[surveys_df['species'].isin([listGoesHere])]`. Use the `isin` function\n",
    "   to find all plots that contain particular species in\n",
    "   the surveys DataFrame. How many records contain these values?\n",
    "3. Experiment with other queries. Create a query that finds all rows with a weight value > or equal to 0.\n",
    "4. The `~` symbol in Python can be used to return the OPPOSITE of the selection that you specify in python. \n",
    "\n",
    "It is equivalent to **is not in**.\n",
    "Write a query that selects all rows that are NOT equal to 'M' or 'F' in the surveys data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# what about our NaN?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Combining data using pandas\n",
    "\n",
    "In many \"real world\" situations, the data that we want to use come in multiple files.\n",
    "We often need to combine these files into a single `DataFrame` to analyze the data.\n",
    "\n",
    "The Pandas package provides various functions for combining DataFrames including `merge` and `concat`.\n",
    "\n",
    "\n",
    "## Concatenating\n",
    "\n",
    "We can use the `concat` function in Pandas to append either columns or rows from one DataFrame to another.\n",
    "Let's grab two subsets of our data to see how this works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save a slice of the first 10 lines of surveys table to a new variable.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save a slice of the last 10 rows to a new variable.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the subset containing the last few rows of the dataframe has an odd index.\n",
    "\n",
    "We can reset this index to be regular sequential indices using the `.reset_index()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the .reset_index() method to 'fix' the index.\n",
    "# What does the `drop` argument do?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we concatenate DataFrames, we need to specify the axis.\n",
    "\n",
    "`axis=0` tells Pandas to stack the second DataFrame under the first one.\n",
    "It will automatically detect whether the column names are the same and will stack accordingly.\n",
    "\n",
    "`axis=1` will stack the columns in the second DataFrame to the RIGHT of the first DataFrame.\n",
    "To stack the data vertically, we need to make sure we have the same columns and associated column format in both datasets.\n",
    "When we stack horizonally, we want to make sure what we are doing makes sense (ie the data are related in some way)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stack the DataFrames on top of each other using the `concat` function.\n",
    "# Save it to a new variable `vertical_stack`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Place the DataFrames side by side\n",
    "# Do we need to reset_index?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge - Row Index Values and Concat\n",
    "\n",
    "Have a look at the vertically stacked dataframe, do you notice anything unusual?\n",
    "\n",
    "The row indexes for the two data frames `surveys_first_10` and `surveys_last_10` are not sequential.\n",
    "\n",
    "Challenges:\n",
    "\n",
    "1. reindex the new concatenated dataframe using the `.reset_index()` method.\n",
    "2. What does `ignore_index` parameter do?\n",
    "   Try entering `pd.concat([surveys_first_10, surveys_last_10], axis=0, ignore_index=True)`\n",
    "3. BONUS. What does `pd.concat([surveys_first_10, surveys_last_10.reset_index(drop=True)], axis=1, ignore_index=True)` do?\n",
    "   How does this relate to the axis joined on?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try out the `ignore_index` parameter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing Out Data to CSV\n",
    "\n",
    "We can use the `.to_csv()` method to do write a `DataFrame` in CSV format.\n",
    "\n",
    "```python\n",
    "vertical_stack.to_csv('out.csv')\n",
    "```\n",
    "\n",
    "Note that the code below will by default save the data into the current working directory.\n",
    "We can save it to a different folder by adding the foldername and a slash to the file string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the vertical_stack dataframe into our current working directory.\n",
    "# What does the `index` parameter do?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check out your working directory to make sure the CSV wrote out properly and that you can open it!\n",
    "If you want, try to bring it back into python to make sure it imports properly.\n",
    "\n",
    "```python\n",
    "# for kicks read our output back into python and make sure all looks good\n",
    "new_output = pd.read_csv('out.csv', keep_default_na=False, na_values=[\"\"])\n",
    "```\n",
    "\n",
    "Or you can use the `%%bash` cell magic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "head out.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joining two `DataFrames`\n",
    "\n",
    "When we concatenated our `DataFrames` we simply added them to each other - stacking them either vertically or side by side.\n",
    "Another way to combine `DataFrames` is to use columns in each dataset that contain common values (a common unique id).\n",
    "\n",
    "Combining `DataFrames` using a common field is called \"joining\".\n",
    "The columns containing the common values are called \"join key(s)\".\n",
    "Joining `DataFrames` in this way is often useful when one `DataFrame` contains additional data that we want to include in the other.\n",
    "\n",
    "NOTE: This process of joining tables is similar to what we do with tables in an SQL database.\n",
    "\n",
    "\n",
    "For example, the file `data/species.csv` file contains additional data about the species we saw in `data/surveys.csv`.\n",
    "This table contains the genus, species and taxa code for 55 species.\n",
    "The species code is unique for each line. These species are identified in our survey data as well using the unique species code.\n",
    "\n",
    "To work through the examples below, we first need to load the species file into a Pandas `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import our surveys and species csvs into dataframes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can see the relationship between the dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the head of surveys_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the head of species_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the column `species_id` in `species_df` corresponds to the `species` column in `surveys_df`.\n",
    "\n",
    "So `species_id` and `species` will be our **join keys**.\n",
    "\n",
    "We can now use the pandas `merge` function to join the two DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Use pd.merge to combine the two dataframes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What's the shape of the output table?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the joined DataFrame now has genera and species information for the survey records.\n",
    "Notice that because the two dataframes both had the column name `species` and we weren't joining on that column, Pandas automatically added `_x` and `_y` to the end of the column names to differentiate them.\n",
    "\n",
    "### Types of joins\n",
    "\n",
    "The most common type of join is called an inner join, which we just did by default with `pd.merge`.\n",
    "An inner join combines two DataFrames based on a join key and returns a new DataFrame that contains only those rows that have matching values in both of the original DataFrames.\n",
    "\n",
    "Inner joins yield a DataFrame that contains only rows where the value being joins exists in BOTH tables.\n",
    "\n",
    "\n",
    "<img src=\"https://datacarpentry.org/python-ecology-lesson/fig/inner-join.png\" alt=\"inner-join\" width=\"450px\" >\n",
    "\n",
    "\n",
    "We can also perform other types of joins like a **left join** by providing the `how` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Perform a left-join using how=\"left\".\n",
    "# What happens if you subset one of the dataframes?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A \"left join\" or \"left outer join\" joins whatever keys it can and fills any missing keys in the \"right\" dataframe with `NaN` values.\n",
    "Unlike the \"inner\" join, none of the rows in the left dataframe are discarded.\n",
    "\n",
    "<img src=\"https://datacarpentry.org/python-ecology-lesson/fig/left-join.png\" alt=\"inner-join\" width=\"450px\" >\n",
    "\n",
    "Other types of join include \"right\" joins and \"full outer joins\".\n",
    "\n",
    "\n",
    "### Challenge\n",
    "\n",
    "In the data folder, there is a `plots.csv` file that contains information about the \"plot type\" associated with each plot.\n",
    "\n",
    "1. Read that data into a pandas dataframe and identify the **join keys** (hint: in `surveys.csv` the column will be `plot`).\n",
    "2. Perform an **inner join** using the `pd.merge` function.\n",
    "2. Find the number of different `species` for each `plot_type` using the `.groupby()` and `.nunique()` methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the plots.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform an inner join of surveys_df and plots_df.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by the plot type and count unique species (or some other summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Automating data processing using For Loops\n",
    "\n",
    "So far, we've used Python and the Pandas library to explore and manipulate individual datasets by hand, much like we would do in a spreadsheet.\n",
    "\n",
    "The beauty of using a programming language like Python comes from the ability to automate data processing through the use of loops and functions.\n",
    "\n",
    "\n",
    "## For loops\n",
    "\n",
    "Loops allow us to repeat a workflow (or series of actions) a given number of times or while some condition is true.\n",
    "We would use a loop to automatically process data that's stored in multiple files E.G. daily values with one file per year.\n",
    "\n",
    "Loops lighten our work load by performing repeated tasks without our direct involvement and make it less likely that we'll introduce errors by making mistakes while processing each file by hand.\n",
    "\n",
    "Let's write a simple for loop that simulates what a kid might see during a visit to the zoo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animals = ['lion', 'tiger', 'crocodile', 'vulture', 'hippo']\n",
    "print(animals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a for loop that prints each animal out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The line defining the loop must start with `for` and end with a colon, and the body of the loop must be indented.\n",
    "\n",
    "In this example, `creature` is the loop variable that takes the value of the next entry in `animals` every time the loop goes around.\n",
    "\n",
    "We can call the loop variable anything we like.\n",
    "After the loop finishes, the loop variable will still exist and will have the value of the last entry in the collection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for creature in animals:\n",
    "    pass\n",
    "\n",
    "creature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are not asking python to print the value of the loop variable anymore, but the for loop still runs and the value of `creature` changes on each pass through the loop.\n",
    "The statement `pass` in the body of the loop just means \"do nothing\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "The file we've been using so far (`surveys.csv`) contains 25 years of data and is\n",
    "very large. We would like to separate the data for each year into a separate\n",
    "file.\n",
    "\n",
    "Let's start by making a new directory called `yearly_files` inside the folder `data` to store all of these files using the function [`mkdir`](https://docs.python.org/3/library/os.html#os.mkdir) in the [`os`](https://docs.python.org/3/library/os.html) module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new directory with the os.mkdir function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that we created the directory with os.listdir\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The command `os.listdir` is equivalent to `ls` in the shell.\n",
    "\n",
    "Previously, we saw how to use the library pandas to load the species\n",
    "data into memory as a DataFrame, how to select a subset of the data using some\n",
    "criteria, and how to write the DataFrame into a csv file. Let's write a script\n",
    "that performs those three steps in sequence for the year 2002:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Load the data into a DataFrame\n",
    "surveys_df = pd.read_csv('data/surveys.csv')\n",
    "\n",
    "# Select only data for 2002\n",
    "surveys2002 = surveys_df.loc[surveys_df[\"year\"] == 2002]\n",
    "\n",
    "# Write the new DataFrame to a csv file\n",
    "surveys2002.to_csv('data/yearly_files/surveys2002.csv')\n",
    "```\n",
    "\n",
    "To create yearly data files, we could repeat the last two commands over and over, once for each year of data.\n",
    "Repeating code is neither elegant nor practical, and is very likely to introduce errors into your code.\n",
    "\n",
    "We want to turn what we've just written into a loop that repeats the last two commands for every year in the dataset.\n",
    "\n",
    "Let's start by writing a loop that simply prints the names of the files we want to create - the dataset we are using covers 1977 through 2002, and we'll create a separate file for each of those years.\n",
    "Listing the filenames is a good way to confirm that the loop is behaving as we expect.\n",
    "\n",
    "We have seen that we can loop over a list of items, so we need a list of years to loop over.\n",
    "\n",
    "We can get the *unique* years in our DataFrame with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the unique years in surveys_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting this into our for loop we get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over the unique years and print them.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can combine strings using the `+` operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the year with strings to produce a new for the full path.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now add the rest of the steps we need to create separate text files.\n",
    "Once finished look inside the `yearly_files` directory and check a couple of the files you\n",
    "just created to confirm that everything worked as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in surveys_df['year'].unique():\n",
    "    # creating filename\n",
    "    \n",
    "    \n",
    "    # extracting data of a specific year\n",
    "    \n",
    "\n",
    "    # writing to file\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the contents of the new folder using os.listdir\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge\n",
    "\n",
    "1. What happens if there is no data for a year in the sequence (for example, imagine we had used 1976 as the start year in `range`)?\n",
    "\n",
    "2. Let's say you only want to look at data from a given multiple of years. How would you modify your loop in order to generate a data file for only every 5th year, starting from 1977? Hint: you will need to use `range` to specify the list of numbers.\n",
    "\n",
    "``` python\n",
    "range(start, end, steps)\n",
    "```\n",
    "\n",
    "3. Instead of splitting out the data by years, a colleague wants to do analyses each species separately. How would you write a unique csv file for each species?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in range(surveys_df['year'].min(), surveys_df['year'].max(), 5):\n",
    "    #creating filename\n",
    "    \n",
    "\n",
    "    # extracting data of a specific year\n",
    "    \n",
    "\n",
    "    # writing to file\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a folder to store species tables!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for species in surveys_df.species.dropna().unique():\n",
    "    # creating filename\n",
    "   \n",
    "\n",
    "    # extracting data of a specific year\n",
    "    \n",
    "\n",
    "    # writing to file\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building reusable and modular code with functions\n",
    "\n",
    "Suppose that separating large data files into individual yearly files is a task that we frequently have to perform.\n",
    "We could write a **for loop** like the one above every time we needed to do it but that would be time consuming and error prone.\n",
    "A more elegant solution would be to create a reusable tool that performs this task with minimum input from the user.\n",
    "To do this, we are going to turn the code we've already written into a function.\n",
    "\n",
    "Functions are reusable, self-contained pieces of code that are called with a single command.\n",
    "They can be designed to accept arguments as input and return values, but they don't need to do either.\n",
    "Variables declared inside functions only exist while the function is running and if a variable within the function (a local variable) has the same name as a variable somewhere else in the code, the local variable hides but doesn't overwrite the other.\n",
    "\n",
    "Every method used in Python (for example, `print`) is a function, and the libraries we import (say, `pandas`) are a collection of functions.\n",
    "\n",
    "We will only use functions that are housed within the same code that uses them, but it's possible [easy to write functions that can be used by different programs](https://docs.python.org/3/tutorial/modules.html).\n",
    "\n",
    "\n",
    "Functions are declared following this general structure:\n",
    "\n",
    "```python\n",
    "def this_is_the_function_name(input_argument1, input_argument2):\n",
    "    # The body of the function is indented\n",
    "\n",
    "    # This function prints the two arguments to screen\n",
    "    print(\n",
    "        'The function arguments are:',\n",
    "        input_argument1,\n",
    "        input_argument2,\n",
    "        '(this is done inside the function!)'\n",
    "    )\n",
    "\n",
    "    # And returns their product\n",
    "    return input_argument1 * input_argument2\n",
    "```\n",
    "\n",
    "The function declaration starts with the word `def`, followed by the function name and any arguments in parenthesis, and ends in a colon.\n",
    "The body of the function is indented just like loops are.\n",
    "\n",
    "If the function returns something when it is called, it includes a return statement at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's define this function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and now let's call the function:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge:\n",
    "\n",
    "2. Try calling the function by giving it the wrong number of arguments (not 2)\n",
    "   or not assigning the function call to a variable (no `product_of_inputs =`)\n",
    "3. Declare a variable inside the function and test to see where it exists (Hint:\n",
    "   can you print it from outside the function?)\n",
    "4. Explore what happens when a variable both inside and outside the function\n",
    "   have the same name. What happens to the global variable when you change the\n",
    "   value of the local variable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "We can now turn our code for saving yearly data files into a function.\n",
    "There are many different \"chunks\" of this code that we can turn into functions, and we can even create functions that call other functions inside them.\n",
    "Let's first write a function that separates data for just one year and saves that data to a file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_year_csv_writer(this_year, all_data):\n",
    "    \"\"\"\n",
    "    Writes a csv file for data from a given year.\n",
    "\n",
    "    this_year --- year for which data is extracted\n",
    "    all_data --- DataFrame with multi-year data\n",
    "    \"\"\"\n",
    "\n",
    "    # Select data for the year\n",
    "    surveys_year = all_data[all_data.year == this_year]\n",
    "\n",
    "    # Write the new DataFrame to a csv file\n",
    "    filename = 'data/yearly_files/function_surveys_year' + str(this_year) + '.csv'\n",
    "    surveys_year.to_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in surveys_df['year'].unique():\n",
    "    one_year_csv_writer(year, surveys_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The text between the two sets of triple double quotes is called a docstring and contains the documentation for the function.\n",
    "It does nothing when the function is running and is therefore not necessary, but it is good practice to include docstrings as a reminder of what the code does.\n",
    "\n",
    "Docstrings in functions also become part of their 'official' documentation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the help for our newly created function\n",
    "help(one_year_csv_writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_year_csv_writer(2002, surveys_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We changed the root of the name of the csv file so we can distinguish it from the one we wrote before.\n",
    "Check the `yearly_files` directory for the file.\n",
    "Did it do what you expect?\n",
    "\n",
    "What we really want to do, though, is create files for multiple years without having to request them one by one.\n",
    "Let's write another function that replaces the entire For loop by simply looping through a sequence of years and repeatedly calling the function we just wrote, `one_year_csv_writer`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yearly_data_csv_writer(start_year, end_year, all_data):\n",
    "    \"\"\"\n",
    "    Writes separate csv files for each year of data.\n",
    "\n",
    "    start_year --- the first year of data we want\n",
    "    end_year --- the last year of data we want\n",
    "    all_data --- DataFrame with multi-year data\n",
    "    \"\"\"\n",
    "\n",
    "    # \"end_year\" is the last year of data we want to pull, so we loop to end_year+1\n",
    "    for year in range(start_year, end_year+1):\n",
    "        one_year_csv_writer(year, all_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because people will naturally expect that the end year for the files is the last\n",
    "year with data, the for loop inside the function ends at `end_year + 1`. \n",
    "This is because when we specify `range()` the last number is not included, try it for yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(range(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By writing the entire loop into a function, we've made a reusable tool for whenever we need to break a large data file into yearly files.\n",
    "Because we can specify the first and last year for which we want files, we can even use this function to create files for a subset of the years available.\n",
    "This is how we call this function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yearly_data_csv_writer(1980, 1990, surveys_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BEWARE!** If you are using IPython Notebooks and you modify a function, you MUST re-run that cell in order for the changed function to be available to the rest of the code.\n",
    "Nothing will visibly happen when you do this, though, because simply defining a function without *calling* it doesn't produce an output.\n",
    "Any cells that use the now-changed functions will also have to be re-run for their output to change.\n",
    "\n",
    "### Challenge:\n",
    "\n",
    "1. **Add two arguments** to the functions we wrote that take the *path* of the\n",
    "   directory where the files will be written and the *root* of the file name.\n",
    "   Create a new set of files with a different name in a different directory.\n",
    "2. Make the functions **return a list** of the files they have written. There are\n",
    "   many ways you can do this (and you should try them all!): either of the\n",
    "   functions can print to screen, either can use a return statement to give back\n",
    "   numbers or strings to their function call, or you can use some combination of\n",
    "   the two. You could also try using the `os` library to list the contents of\n",
    "   directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding two arguments\n",
    "def one_year_csv_writer(all_data, directory, file_root, this_year=1977):\n",
    "    \"\"\"\n",
    "    Writes a csv file for data from a given year in the speciefied directory using specified root name\n",
    "\n",
    "    this_year --- year for which data is extracted --- default: 1977\n",
    "    all_data --- DataFrame with multi-year data\n",
    "    directory --- directory in which the data is to be saved, include the /\n",
    "    file_root --- prefix for the filename [prefix_year.csv], include any _ wanted\n",
    "    \"\"\"\n",
    "\n",
    "    # Select data for the year\n",
    "    surveys_year = all_data[all_data.year == this_year]\n",
    "\n",
    "    # Write the new DataFrame to a csv file\n",
    "    filename =  directory + file_root + str(this_year) + '.csv'\n",
    "    surveys_year.to_csv(filename)\n",
    "\n",
    "\n",
    "def yearly_data_csv_writer(all_data, directory, file_root, start_year=1977, end_year=2002):\n",
    "    \"\"\"\n",
    "    Writes separate csv files for each year of data.\n",
    "\n",
    "    start_year --- the first year of data we want --- default: 1977\n",
    "    end_year --- the last year of data we want --- default: 2002\n",
    "    all_data --- DataFrame with multi-year data\n",
    "    directory --- directory in which the data is to be saved, include the /\n",
    "    file_root --- prefix for the filename [prefix_year.csv], include any _ wanted\n",
    "    \"\"\"\n",
    "\n",
    "    # \"end_year\" is the last year of data we want to pull, so we loop to end_year+1\n",
    "    for year in range(start_year, end_year+1):\n",
    "        one_year_csv_writer(year, all_data, directory, file_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding the list of filenames\n",
    "def one_year_csv_writer(all_data, directory, file_root, this_year=1977):\n",
    "    \"\"\"\n",
    "    Writes a csv file for data from a given year in the speciefied directory using specified root name\n",
    "\n",
    "    this_year --- year for which data is extracted --- default: 1977\n",
    "    all_data --- DataFrame with multi-year data\n",
    "    directory --- directory in which the data is to be saved, include the /\n",
    "    file_root --- prefix for the filename [prefix_year.csv], include any _ wanted\n",
    "    \"\"\"\n",
    "\n",
    "    # Select data for the year\n",
    "    surveys_year = all_data[all_data.year == this_year]\n",
    "\n",
    "    # Write the new DataFrame to a csv file\n",
    "    filename =  directory + file_root + str(this_year) + '.csv'\n",
    "    surveys_year.to_csv(filename)\n",
    "    return(filename)\n",
    "\n",
    "\n",
    "def yearly_data_csv_writer(all_data, directory, file_root, start_year=1977, end_year=2002):\n",
    "    \"\"\"\n",
    "    Writes separate csv files for each year of data.\n",
    "\n",
    "    start_year --- the first year of data we want --- default: 1977\n",
    "    end_year --- the last year of data we want --- default: 2002\n",
    "    all_data --- DataFrame with multi-year data\n",
    "    directory --- directory in which the data is to be saved, include the /\n",
    "    file_root --- prefix for the filename [prefix_year.csv], include any _ wanted\n",
    "    \"\"\"\n",
    "    fname = []\n",
    "    # \"end_year\" is the last year of data we want to pull, so we loop to end_year+1\n",
    "    for year in range(start_year, end_year+1):\n",
    "        fname.append(one_year_csv_writer(year, all_data, directory, file_root))\n",
    "    return(fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "But what if our dataset doesn't start in 1977 and end in 2002? We can modify the\n",
    "function so that it looks for the start and end years in the dataset if those\n",
    "dates are not provided:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function\n",
    "def yearly_data_arg_test(all_data, start_year=None, end_year=None):\n",
    "    \"\"\"\n",
    "    Modified from yearly_data_csv_writer to test default argument values!\n",
    "\n",
    "    start_year --- the first year of data we want --- default: None - check all_data\n",
    "    end_year --- the last year of data we want --- default: None - check all_data\n",
    "    all_data --- DataFrame with multi-year data\n",
    "    \"\"\"\n",
    "\n",
    "    if start_year is None:\n",
    "        start_year = min(all_data.year)\n",
    "    if end_year is None:\n",
    "        end_year = max(all_data.year)\n",
    "\n",
    "    return start_year, end_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default values of the `start_year` and `end_year` arguments in the function `yearly_data_arg_test` are now `None`.\n",
    "This is a build-it constant in Python\n",
    "that indicates the absence of a value - essentially, that the variable exists in\n",
    "the namespace of the function (the directory of variable names) but that it\n",
    "doesn't correspond to any existing object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The body of the test function now has two conditional blocks (**if statement**) that\n",
    "check the values of `start_year` and `end_year`. If statements execute the body of\n",
    "the 'block' when some condition is met. \n",
    "\n",
    "\n",
    "### Conditions\n",
    "\n",
    "`if` statements work like the boolean logic we saw earlier when we created masks to select our data.\n",
    "They commonly look something like this:\n",
    "\n",
    "```python\n",
    "favourite = \"apple\"\n",
    "\n",
    "if favourite == \"apple\":  # meets first condition?\n",
    "    print(\"Ace! I love apples!\")\n",
    "\n",
    "elif favourite == \"banana\":  # did not meet first condition. meets second condition?\n",
    "    print(\"I'm bonkers for bananas too!\")\n",
    "\n",
    "# did not meet first or second condition. meets third condition?\n",
    "elif favourite == \"durian\":\n",
    "    print(\"Ohh...\")\n",
    "\n",
    "else:  # met no conditions\n",
    "    print(\"I've never heard of that fruit.\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an if statement that checks if a value `a` is positive, negative or zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the value of `a` to see how this function works.\n",
    "The statement `elif` means \"else if\", and all of the conditional statements must end in a colon.\n",
    "\n",
    "The `if` statements in the function `yearly_data_arg_test` check whether there is an object associated with the variable names `start_year` and `end_year`.\n",
    "If those variables are `None`, the if statements return the boolean `True` and execute whatever is in their body.\n",
    "On the other hand, if the variable names are associated with some value (they got a number in the function call), the if statements return `False` and do not execute.\n",
    "The opposite conditional statements, which would return `True` if the variables were associated with objects (if they had received value in the function call), would be `if start_year` and `if end_year`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge:\n",
    "\n",
    "1. Rewrite the `one_year_csv_writer` and `yearly_data_csv_writer` functions to use `None` as default for the years.\n",
    "2. The code below has statements that could overlap.\n",
    "\n",
    "    ```python\n",
    "    a = 11\n",
    "\n",
    "    if a == 11:\n",
    "            print(\"Legs eleven!\")\n",
    "    elif a > 0:\n",
    "        print(\"a is positive\")\n",
    "    else:\n",
    "        print(\"a is zero or negative\")\n",
    "    ```\n",
    "\n",
    "    What happens if we swap the first two statements?\n",
    "    \n",
    "    ```python\n",
    "    a = 11\n",
    "\n",
    "    if a > 0:\n",
    "        print(\"a is positive\")\n",
    "    elif a == 11:\n",
    "        print(\"Legs eleven!\")\n",
    "    else:\n",
    "        print(\"a is zero or negative\")\n",
    "    ```\n",
    "\n",
    "    Do you get the same result?\n",
    "\n",
    "3. Modify the functions so that they don't create yearly files if there is no\n",
    "   data for a given year and display an alert to the user (Hint: use conditional\n",
    "   statements to do this)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 06 - Seaborn and matplotlib\n",
    "\n",
    "[Matplotlib](https://matplotlib.org/) is an extremely flexible plotting package for Python, but it lacks an intuitive interface and the default plots are a bit unpleasant.\n",
    "\n",
    "There are many libraries that build on top of the matplotlib foundations to provide a more convenient way to visualise data.\n",
    "We already saw Pandas' `.plot()` method, which calls some matplotlib functions.\n",
    "Other popular libraries include [plotnine](https://plotnine.readthedocs.io/en/stable/) which works a little bit like [`ggplot2`](https://ggplot2.tidyverse.org/) in R.\n",
    "\n",
    "Here we'll look more at some examples from another package called [seaborn](https://seaborn.pydata.org/index.html) which has some great tutorials and an [example gallery](https://seaborn.pydata.org/examples/index.html) with code to pick and choose from.\n",
    "\n",
    "Lets load seaborn and recreate some earlier plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=\"year\", y=\"wgt\", data=surveys_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can tell the package to use a more \"ggplot\"-like stype using the `set` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the style to \"darkgrid\" using set. \n",
    "sns.set(style=\"ticks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the same scatterplot\n",
    "sns.scatterplot(x=\"year\", y=\"wgt\", data=surveys_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we can plot a bar chart of summaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group surveys_df by sex and species and plot the mean weights.\n",
    "mean_weights = surveys_df.groupby([\"sex\", \"species\"])[\"wgt\"].mean().reset_index()\n",
    "sns.barplot(x=\"species\", y=\"wgt\", hue=\"sex\", data=mean_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
